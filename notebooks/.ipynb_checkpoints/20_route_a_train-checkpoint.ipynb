{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b932a1",
   "metadata": {},
   "source": [
    "# route a: dense kda hybrid\n",
    "\n",
    "small-scale runs and config iteration.\n",
    "\n",
    "all model implementations are in pytorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff64e6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## run checklist\n",
    "- select dataset snapshot tag and tokenizer version\n",
    "- set kda/full attention ratio to 3:1\n",
    "- run a short smoke train and confirm loss decreases\n",
    "- save and reload a checkpoint before full runs\n",
    "\n",
    "## config sketch\n",
    "- target ~100m params by adjusting depth/width\n",
    "- tie embeddings if needed to hit the budget\n",
    "- log evals at regular token intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c495bf-f05e-45c0-9c09-411310366222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797942ed-5b36-4cdf-b4dd-2cdf193376b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51daf039-9213-4255-a3a2-40ef6ead5892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bb32448-b5fd-4030-af07-07c17efb6abe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## check manifests and cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4b413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifest entries 1\n",
      "cuda available True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "data_root = Path(\"../data\")\n",
    "manifest_path = data_root / \"stages\" / \"stage1\" / \"manifest.jsonl\"\n",
    "\n",
    "def load_manifest(path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"missing manifest: {path}\")\n",
    "    with open(path, \"r\") as f:\n",
    "        return [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "manifest = load_manifest(manifest_path)\n",
    "print(\"manifest entries\", len(manifest))\n",
    "print(\"cuda available\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ec07a-5eb3-4e4e-a20d-4af25ca13a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306c451-ed00-49e5-a318-4e14c98155ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84b6f4-e914-4093-a8e1-c4859f0d7515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a066f7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## data sampling preview\n",
    "this cell tokenizes a few lines for a visual sanity check before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edcff589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples\n",
      "- No. 24; Updated March 2011\n",
      "Click here to download and print a PDF version of this document.\n",
      "Parents are usually the firs\n",
      "- Previous abstract Next abstract\n",
      "Session 40 - The Interstellar Medium.\n",
      "Display session, Tuesday, June 09\n",
      "Gamma Ray Burst \n",
      "- Question: How is bipolar disorder different from unipolar depression or 'regular' depression?\n",
      "Answer: Both bipolar disor\n",
      "- Making the Case for Action\n",
      "This fact sheet(pdf) and slide deck provide essential state-specific information that address\n",
      "- A land whose rich cultural heritage is discovered not only from within the walls of numerous museums, galleries and chur\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "processed_dir = Path(\"../data/processed\")\n",
    "shards = sorted(processed_dir.glob(\"stage1_shard_*.jsonl\"))\n",
    "lengths = []\n",
    "examples = []\n",
    "\n",
    "if not shards:\n",
    "    print(\"no shards found\")\n",
    "else:\n",
    "    with open(shards[0], \"r\") as f:\n",
    "        for i, line in zip(range(5), f):\n",
    "            text = json.loads(line).get(\"text\")\n",
    "            if text is None:\n",
    "                continue\n",
    "            if not isinstance(text, str):\n",
    "                text = str(text)\n",
    "            examples.append(text)\n",
    "        for i, line in zip(range(200), f):\n",
    "            text = json.loads(line).get(\"text\")\n",
    "            if text is None:\n",
    "                continue\n",
    "            if not isinstance(text, str):\n",
    "                text = str(text)\n",
    "            lengths.append(len(enc.encode(text)))\n",
    "\n",
    "print(\"examples\")\n",
    "for ex in examples:\n",
    "    print(\"-\", ex[:120])\n",
    "\n",
    "if lengths:\n",
    "    plt.hist(lengths, bins=30)\n",
    "    plt.title(\"token lengths (sample)\")\n",
    "    plt.xlabel(\"tokens\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"no lengths to plot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a9794-4b5e-489b-bddf-021e4f205ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7234c0-ae96-437f-a625-028de468ed5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edc808-dd94-495d-9b11-c2aa9729e4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26d0ca0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## training stub (single step)\n",
    "this runs one forward/backward step on a tiny lm to validate the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b528c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "loss 11.049959182739258\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# from pathlib import Path\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import tiktoken\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# enc = tiktoken.get_encoding(\"gpt2\")\n",
    "# block_size = 64\n",
    "# batch_size = 4\n",
    "# max_lines = 50\n",
    "\n",
    "# def load_texts(shard_path, limit):\n",
    "#     texts = []\n",
    "#     with open(shard_path, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             if len(texts) >= limit:\n",
    "#                 break\n",
    "#             text = json.loads(line).get(\"text\")\n",
    "#             if text is None:\n",
    "#                 continue\n",
    "#             if not isinstance(text, str):\n",
    "#                 text = str(text)\n",
    "#             texts.append(text)\n",
    "#     return texts\n",
    "\n",
    "# processed_dir = Path(\"../data/processed\")\n",
    "# shards = sorted(processed_dir.glob(\"stage1_shard_*.jsonl\"))\n",
    "# if not shards:\n",
    "#     raise FileNotFoundError(\"no processed shards found\")\n",
    "# texts = load_texts(shards[0], max_lines)\n",
    "# tokens = []\n",
    "# for text in texts:\n",
    "#     tokens.extend(enc.encode(text))\n",
    "# data = torch.tensor(tokens, dtype=torch.long)\n",
    "# if data.numel() <= block_size + 1:\n",
    "#     raise ValueError(\"not enough tokens for a batch\")\n",
    "\n",
    "# def get_batch():\n",
    "#     idx = torch.randint(0, data.numel() - block_size - 1, (batch_size,))\n",
    "#     x = torch.stack([data[i : i + block_size] for i in idx])\n",
    "#     y = torch.stack([data[i + 1 : i + block_size + 1] for i in idx])\n",
    "#     return x.to(device), y.to(device)\n",
    "\n",
    "# class TinyLM(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_dim):\n",
    "#         super().__init__()\n",
    "#         self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "#         self.lm_head = nn.Linear(embed_dim, vocab_size, bias=False)\n",
    "#     def forward(self, x):\n",
    "#         h = self.embed(x)\n",
    "#         return self.lm_head(h)\n",
    "\n",
    "# model = TinyLM(enc.n_vocab, 128).to(device)\n",
    "# opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "# x, y = get_batch()\n",
    "# logits = model(x)\n",
    "# loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "# loss.backward()\n",
    "# opt.step()\n",
    "# print(\"device\", device)\n",
    "# print(\"loss\", float(loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0fa1a2-2780-46a0-bb8e-f98313b0736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eccecf-5295-4c35-b5db-68a4d18ab1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e1e81-b864-4a9d-b094-57b70e1ccf70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bdfec5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## token sample decode\n",
    "this shows a decoded snippet from the token stream for sanity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230f59e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded sample\n",
      "No. 24; Updated March 2011\n",
      "Click here to download and print a PDF version of this document.\n",
      "Parents are usually the first to recognize that their child has a problem with emotions or behavior. Still, the decision to seek professional help can be difficult and painful for a parent. The first step is to gently try to talk to the child. An honest open talk about feelings can often help. Parents may choose to consult with the child's physicians, teachers, members of the clergy, or other adults who k\n"
     ]
    }
   ],
   "source": [
    "# import tiktoken\n",
    "# import torch\n",
    "\n",
    "# enc = tiktoken.get_encoding(\"gpt2\")\n",
    "# sample_tokens = data[:200].tolist()\n",
    "# decoded = enc.decode(sample_tokens)\n",
    "# print(\"decoded sample\")\n",
    "# print(decoded[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af7ea1-8b70-43f6-96b2-ab4449761179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d230d6-7864-4467-a6aa-1a1c16236b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624f22b-d6e2-4bcd-9c72-906c7f5f87b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa4e63f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## mini loss curve (5 steps)\n",
    "this runs a tiny loop to visualize loss movement on the sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704432be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# model.train()\n",
    "# losses = []\n",
    "# steps = 5\n",
    "# for _ in range(steps):\n",
    "#     x, y = get_batch()\n",
    "#     logits = model(x)\n",
    "#     loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "#     opt.zero_grad()\n",
    "#     loss.backward()\n",
    "#     opt.step()\n",
    "#     losses.append(float(loss.item()))\n",
    "# plt.plot(range(1, steps + 1), losses, marker=\"o\")\n",
    "# plt.title(\"mini loss curve\")\n",
    "# plt.xlabel(\"step\")\n",
    "# plt.ylabel(\"loss\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4483c4-f984-4a04-a73c-508129400e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5184ae-6b83-468d-837f-4a1f677fbe5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a99089-2e87-4450-b834-21add60af52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db17d46b",
   "metadata": {},
   "source": [
    "## model + training config (route a)\n",
    "this config targets ~100m params and supports partial training on the manifest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0724a736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'vocab_size': 50257,\n",
       "  'block_size': 256,\n",
       "  'n_layer': 6,\n",
       "  'n_head': 12,\n",
       "  'n_embd': 768,\n",
       "  'alpha_rank': 64,\n",
       "  'kda_chunk_size': 64,\n",
       "  'kda_ratio': 3,\n",
       "  'use_pos_emb': False},\n",
       " {'batch_size': 2,\n",
       "  'grad_accum_steps': 1,\n",
       "  'max_steps': 200,\n",
       "  'max_tokens': 200000,\n",
       "  'lr': 0.0003,\n",
       "  'log_interval': 10})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"block_size\": 256,\n",
    "    \"n_layer\": 6,\n",
    "    \"n_head\": 12,\n",
    "    \"n_embd\": 768,\n",
    "    \"alpha_rank\": 64,\n",
    "    \"kda_chunk_size\": 64,\n",
    "    \"kda_ratio\": 3,\n",
    "    \"use_pos_emb\": False,\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    \"batch_size\": 2,\n",
    "    \"grad_accum_steps\": 1,\n",
    "    \"max_steps\": 200,\n",
    "    \"max_tokens\": 200_000,\n",
    "    \"lr\": 3e-4,\n",
    "    \"log_interval\": 10,\n",
    "}\n",
    "model_config, train_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dbc092",
   "metadata": {},
   "source": [
    "## kda attention (chunked)\n",
    "this is a direct, unoptimized pytorch implementation based on kda.pdf listing 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79c99082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def chunk_kda(q, k, v, g, beta, chunk_size):\n",
    "    dtype = v.dtype\n",
    "    b, t, h, kdim = q.shape\n",
    "    vdim = v.shape[-1]\n",
    "    c = chunk_size\n",
    "    n = t // c\n",
    "    t_trunc = n * c\n",
    "    q = q[:, :t_trunc]\n",
    "    k = k[:, :t_trunc]\n",
    "    v = v[:, :t_trunc]\n",
    "    g = g[:, :t_trunc]\n",
    "    beta = beta[:, :t_trunc]\n",
    "    q = q.view(b, n, c, h, kdim).permute(0, 3, 1, 2, 4).to(torch.float32)\n",
    "    k = k.view(b, n, c, h, kdim).permute(0, 3, 1, 2, 4).to(torch.float32)\n",
    "    v = v.view(b, n, c, h, vdim).permute(0, 3, 1, 2, 4).to(torch.float32)\n",
    "    g = g.view(b, n, c, h, kdim).permute(0, 3, 1, 2, 4).to(torch.float32)\n",
    "    beta = beta.view(b, n, c, h).permute(0, 3, 1, 2).to(torch.float32)\n",
    "    q = q * (kdim ** -0.5)\n",
    "    g = g.cumsum(-2)\n",
    "    mask = torch.triu(torch.ones(c, c, dtype=torch.bool, device=q.device), diagonal=0)\n",
    "    a = torch.zeros(b, h, n, c, c, dtype=torch.float32, device=q.device)\n",
    "    for i in range(c):\n",
    "        k_i = k[..., i, :]\n",
    "        g_i = g[..., i:i+1, :]\n",
    "        a[..., i] = torch.einsum(\"... c d, ... d -> ... c\", k * (g - g_i).exp(), k_i)\n",
    "    a = a * beta[..., None]\n",
    "    a = -a.masked_fill(mask, 0)\n",
    "    for i in range(1, c):\n",
    "        a[..., i, :i] = a[..., i, :i].clone() + (a[..., i, :, None].clone() * a[..., :i].clone()).sum(-2)\n",
    "    a = (a + torch.eye(c, dtype=torch.float32, device=q.device)) * beta[..., None, :]\n",
    "    if not torch.isfinite(a).all():\n",
    "        print(\"non-finite a\")\n",
    "        return torch.zeros((b, t_trunc, h, vdim), device=q.device, dtype=dtype)\n",
    "    w = torch.einsum(\"... i j, ... j d -> ... i d\", a, g.exp() * k)\n",
    "    if not torch.isfinite(w).all():\n",
    "        print(\"non-finite w\")\n",
    "        return torch.zeros((b, t_trunc, h, vdim), device=q.device, dtype=dtype)\n",
    "    u = torch.einsum(\"... i j, ... j d -> ... i d\", a, v)\n",
    "    if not torch.isfinite(u).all():\n",
    "        print(\"non-finite u\")\n",
    "        return torch.zeros((b, t_trunc, h, vdim), device=q.device, dtype=dtype)\n",
    "    s = k.new_zeros(b, h, kdim, vdim)\n",
    "    o = torch.zeros_like(v)\n",
    "    mask = torch.triu(torch.ones(c, c, dtype=torch.bool, device=q.device), diagonal=1)\n",
    "    for i in range(0, n):\n",
    "        q_i, k_i, u_i, g_i, w_i = q[:, :, i], k[:, :, i], u[:, :, i], g[:, :, i], w[:, :, i]\n",
    "        a = torch.zeros(b, h, c, c, dtype=torch.float32, device=q.device)\n",
    "        for j in range(c):\n",
    "            k_j = k[:, :, i, j]\n",
    "            g_j = g[:, :, i, j:j+1, :]\n",
    "            a[..., j] = torch.einsum(\"... c d, ... d -> ... c\", q_i * (g_i - g_j).exp(), k_j)\n",
    "        a = a.masked_fill(mask, 0)\n",
    "        v_i = u_i - torch.einsum(\"... i j, ... j d -> ... i d\", w_i, s)\n",
    "        o[:, :, i] = torch.einsum(\"... c d, ... d v -> ... c v\", q_i * g_i.exp(), s) + torch.einsum(\"... i j, ... j d -> ... i d\", a, v_i)\n",
    "        s = s * g_i[:, :, -1].exp().unsqueeze(-1)\n",
    "        if not torch.isfinite(s).all():\n",
    "            print(\"non-finite s\")\n",
    "            return torch.zeros((b, t_trunc, h, vdim), device=q.device, dtype=dtype)\n",
    "        s = s + torch.einsum(\"... c d, ... c v -> ... d v\", (g_i[:, :, -1:] - g_i).exp() * k_i, v_i)\n",
    "    o = o.permute(0, 2, 3, 1, 4).contiguous().view(b, t_trunc, h, vdim)\n",
    "    return o.to(dtype)\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        rms = x.pow(2).mean(dim=-1, keepdim=True).add(self.eps).sqrt()\n",
    "        return (x / rms) * self.weight\n",
    "\n",
    "class ShortConv1d(nn.Module):\n",
    "    def __init__(self, dim, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, kernel_size=kernel_size, padding=kernel_size // 2, groups=dim)\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv(x)\n",
    "        return x.transpose(1, 2)\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "def l2norm(x, eps=1e-6):\n",
    "    return x / (x.norm(dim=-1, keepdim=True) + eps)\n",
    "\n",
    "class KDAAttention(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, chunk_size, alpha_rank=64):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = n_embd // n_head\n",
    "        self.chunk_size = chunk_size\n",
    "        self.q_proj = nn.Linear(n_embd, n_embd)\n",
    "        self.k_proj = nn.Linear(n_embd, n_embd)\n",
    "        self.v_proj = nn.Linear(n_embd, n_embd)\n",
    "        self.q_conv = ShortConv1d(n_embd)\n",
    "        self.k_conv = ShortConv1d(n_embd)\n",
    "        self.v_conv = ShortConv1d(n_embd)\n",
    "        self.alpha_down = nn.Linear(n_embd, alpha_rank)\n",
    "        self.alpha_up = nn.Linear(alpha_rank, n_embd)\n",
    "        self.beta_proj = nn.Linear(n_embd, n_head)\n",
    "        self.out_gate_down = nn.Linear(n_embd, alpha_rank)\n",
    "        self.out_gate_up = nn.Linear(alpha_rank, n_embd)\n",
    "        self.rms = RMSNorm(n_embd)\n",
    "        self.out_proj = nn.Linear(n_embd, n_embd)\n",
    "        alpha_init = 0.98\n",
    "        beta_init = 0.1\n",
    "        alpha_init_bias = math.log(alpha_init / (1.0 - alpha_init))\n",
    "        beta_init_bias = math.log(beta_init / (1.0 - beta_init))\n",
    "        with torch.no_grad():\n",
    "            self.alpha_up.bias.fill_(alpha_init_bias)\n",
    "            self.beta_proj.bias.fill_(beta_init_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape\n",
    "        q = l2norm(swish(self.q_conv(self.q_proj(x))))\n",
    "        k = l2norm(swish(self.k_conv(self.k_proj(x))))\n",
    "        v = swish(self.v_conv(self.v_proj(x)))\n",
    "        q = q.view(b, t, self.n_head, self.head_dim)\n",
    "        k = k.view(b, t, self.n_head, self.head_dim)\n",
    "        v = v.view(b, t, self.n_head, self.head_dim)\n",
    "        alpha = torch.sigmoid(self.alpha_up(swish(self.alpha_down(x))))\n",
    "        alpha = alpha.clamp(min=1e-4, max=1.0 - 1e-4)\n",
    "        alpha = alpha.view(b, t, self.n_head, self.head_dim)\n",
    "        g = torch.log(alpha + 1e-6)\n",
    "        beta = torch.sigmoid(self.beta_proj(x)).view(b, t, self.n_head)\n",
    "        o = chunk_kda(q, k, v, g, beta, self.chunk_size)\n",
    "        o = o.reshape(b, t, c)\n",
    "        gate = torch.sigmoid(self.out_gate_up(swish(self.out_gate_down(x))))\n",
    "        o = self.rms(o) * gate\n",
    "        return self.out_proj(o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2a463",
   "metadata": {},
   "source": [
    "## transformer blocks (kda + full attention 3:1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "053eb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = n_embd // n_head\n",
    "        self.qkv = nn.Linear(n_embd, 3 * n_embd)\n",
    "        self.out_proj = nn.Linear(n_embd, n_embd)\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.split(c, dim=-1)\n",
    "        q = q.view(b, t, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(b, t, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(b, t, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        att = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)\n",
    "        mask = torch.triu(torch.ones(t, t, device=x.device), diagonal=1).bool()\n",
    "        att = att.masked_fill(mask, float(\"-inf\"))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(b, t, c)\n",
    "        return self.out_proj(y)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_embd, expansion=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_embd, expansion * n_embd)\n",
    "        self.fc2 = nn.Linear(expansion * n_embd, n_embd)\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.gelu(self.fc1(x)))\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, use_kda, chunk_size):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        self.attn = KDAAttention(n_embd, n_head, chunk_size, alpha_rank=64) if use_kda else CausalSelfAttention(n_embd, n_head)\n",
    "        self.mlp = MLP(n_embd)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class KDALanguageModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"n_embd\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"block_size\"], cfg[\"n_embd\"])\n",
    "        self.use_pos_emb = cfg.get(\"use_pos_emb\", True)\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(cfg[\"n_layer\"]):\n",
    "            use_kda = (i % (cfg[\"kda_ratio\"] + 1)) != cfg[\"kda_ratio\"]\n",
    "            self.blocks.append(Block(cfg[\"n_embd\"], cfg[\"n_head\"], use_kda, cfg[\"kda_chunk_size\"]))\n",
    "        self.ln_f = nn.LayerNorm(cfg[\"n_embd\"])\n",
    "        self.lm_head = nn.Linear(cfg[\"n_embd\"], cfg[\"vocab_size\"], bias=False)\n",
    "    def forward(self, idx, targets=None):\n",
    "        b, t = idx.shape\n",
    "        if t > self.cfg[\"block_size\"]:\n",
    "            raise ValueError(\"sequence too long\")\n",
    "        pos = torch.arange(0, t, device=idx.device)\n",
    "        x = self.tok_emb(idx)\n",
    "        if self.use_pos_emb:\n",
    "            x = x + self.pos_emb(pos)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c770e3b8-7355-4884-8942-401075fe7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_count 121007548\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = KDALanguageModel(model_config).to(device)\n",
    "print(\"param_count\", count_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc9b7c-3369-425b-909a-6622292b9e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcafef2-e068-4e93-b5c9-78c8f6708100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab230a00-4c44-4205-8840-1d3bae747931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "122e377f",
   "metadata": {},
   "source": [
    "## training loop (route a)\n",
    "prints loss, step time, and tokens/sec for quick feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f87799c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 loss 11.0066 step_time 1.269s tok/s 403.6\n",
      "step 10 loss 4.8521 step_time 0.690s tok/s 742.3\n",
      "step 20 loss 8.2851 step_time 0.696s tok/s 735.4\n",
      "step 30 loss 4.5728 step_time 0.696s tok/s 736.1\n",
      "step 40 loss 4.7091 step_time 0.718s tok/s 712.7\n",
      "step 50 loss 1.8171 step_time 0.720s tok/s 710.6\n",
      "step 60 loss 4.7792 step_time 0.703s tok/s 728.5\n",
      "step 70 loss 5.9736 step_time 0.719s tok/s 712.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m t0 = time.time()\n\u001b[32m     39\u001b[39m x, y = get_batch()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.isfinite(loss).item():\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan loss at step\u001b[39m\u001b[33m\"\u001b[39m, step)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mKDALanguageModel.forward\u001b[39m\u001b[34m(self, idx, targets)\u001b[39m\n\u001b[32m     63\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.pos_emb(pos)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m x = \u001b[38;5;28mself\u001b[39m.ln_f(x)\n\u001b[32m     67\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.lm_head(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.mlp(\u001b[38;5;28mself\u001b[39m.ln2(x))\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 131\u001b[39m, in \u001b[36mKDAAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    129\u001b[39m g = torch.log(alpha + \u001b[32m1e-6\u001b[39m)\n\u001b[32m    130\u001b[39m beta = torch.sigmoid(\u001b[38;5;28mself\u001b[39m.beta_proj(x)).view(b, t, \u001b[38;5;28mself\u001b[39m.n_head)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m o = \u001b[43mchunk_kda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m o = o.reshape(b, t, c)\n\u001b[32m    133\u001b[39m gate = torch.sigmoid(\u001b[38;5;28mself\u001b[39m.out_gate_up(swish(\u001b[38;5;28mself\u001b[39m.out_gate_down(x))))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mchunk_kda\u001b[39m\u001b[34m(q, k, v, g, beta, chunk_size)\u001b[39m\n\u001b[32m     54\u001b[39m     k_j = k[:, :, i, j]\n\u001b[32m     55\u001b[39m     g_j = g[:, :, i, j:j+\u001b[32m1\u001b[39m, :]\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     a[..., j] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m... c d, ... d -> ... c\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_i\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_i\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_j\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m a = a.masked_fill(mask, \u001b[32m0\u001b[39m)\n\u001b[32m     58\u001b[39m v_i = u_i - torch.einsum(\u001b[33m\"\u001b[39m\u001b[33m... i j, ... j d -> ... i d\u001b[39m\u001b[33m\"\u001b[39m, w_i, s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/torch/functional.py:373\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, *_operands)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum.enabled:\n\u001b[32m    371\u001b[39m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[32m    372\u001b[39m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    375\u001b[39m path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum.is_available():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3419\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3414\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.store_output(execution_count)\n\u001b[32m   3415\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3416\u001b[39m         \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3417\u001b[39m         \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[\n\u001b[32m   3418\u001b[39m             execution_count\n\u001b[32m-> \u001b[39m\u001b[32m3419\u001b[39m         ] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3469\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3466\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3467\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3468\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3469\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3470\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3471\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3472\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3473\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3474\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py:1193\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1192\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py:1064\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1061\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1063\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1070\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1071\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1079\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1080\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py:872\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    864\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    865\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    870\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    871\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m872\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    877\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py:784\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    774\u001b[39m         frames.append(\n\u001b[32m    775\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    776\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    781\u001b[39m             )\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    786\u001b[39m     frames.append(\n\u001b[32m    787\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    788\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m         )\n\u001b[32m    794\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py:659\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    656\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    657\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m )\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/IPython/core/tbtools.py:100\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     99\u001b[39m lineno = stack_line.lineno\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    103\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/stack_data/core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/stack_data/core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/stack_data/utils.py:164\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    161\u001b[39m             length += \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[32m    162\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m ttype, value\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m lexer = \u001b[43mMyLexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstripnl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    166\u001b[39m     highlighted = pygments.highlight(code, lexer, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/lexer.py:660\u001b[39m, in \u001b[36mRegexLexerMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwds)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m         \u001b[38;5;28mcls\u001b[39m._tokens = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_tokendef\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tokendefs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m.\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/lexer.py:599\u001b[39m, in \u001b[36mRegexLexerMeta.process_tokendef\u001b[39m\u001b[34m(cls, name, tokendefs)\u001b[39m\n\u001b[32m    597\u001b[39m tokendefs = tokendefs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.tokens[name]\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tokendefs):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokendefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/lexer.py:579\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tdef) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwrong rule def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     rex = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muncompilable regex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m in state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/lexer.py:507\u001b[39m, in \u001b[36mRegexLexerMeta._process_regex\u001b[39m\u001b[34m(cls, regex, rflags, state)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Preprocess the regular expression component of a token definition.\"\"\"\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(regex, Future):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     regex = \u001b[43mregex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m re.compile(regex, rflags).match\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/lexer.py:495\u001b[39m, in \u001b[36mwords.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregex_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:91\u001b[39m, in \u001b[36mregex_opt\u001b[39m\u001b[34m(strings, prefix, suffix)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a compiled regex that matches any string in the given list.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m     85\u001b[39m \u001b[33;03mThe strings to match must be literal strings, not regexes.  They will be\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m*prefix* and *suffix* are pre- and appended to the final regex.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     90\u001b[39m strings = \u001b[38;5;28msorted\u001b[39m(strings)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prefix + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m + suffix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "    \u001b[31m[... skipping similar frames: <genexpr> at line 77 (3 times), regex_opt_inner at line 77 (3 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smol-lm/.venv/lib/python3.13/site-packages/pygments/regexopt.py:57\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;66;03m# print '-> only 1-character'\u001b[39;00m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + make_charset(oneletter) + close_paren\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m prefix = \u001b[43mcommonprefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix:\n\u001b[32m     59\u001b[39m     plen = \u001b[38;5;28mlen\u001b[39m(prefix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen genericpath>:114\u001b[39m, in \u001b[36mcommonprefix\u001b[39m\u001b[34m(m)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "processed_dir = Path(\"../data/processed\")\n",
    "shards = sorted(processed_dir.glob(\"stage1_shard_*.jsonl\"))\n",
    "if not shards:\n",
    "    raise FileNotFoundError(\"no processed shards found\")\n",
    "\n",
    "def load_tokens(max_tokens):\n",
    "    tokens = []\n",
    "    for shard in shards:\n",
    "        with open(shard, \"r\") as f:\n",
    "            for line in f:\n",
    "                text = json.loads(line).get(\"text\")\n",
    "                if text is None:\n",
    "                    continue\n",
    "                if not isinstance(text, str):\n",
    "                    text = str(text)\n",
    "                tokens.extend(enc.encode(text))\n",
    "                if max_tokens and len(tokens) >= max_tokens:\n",
    "                    return torch.tensor(tokens[:max_tokens], dtype=torch.long)\n",
    "    return torch.tensor(tokens, dtype=torch.long)\n",
    "\n",
    "token_data = load_tokens(train_config[\"max_tokens\"])\n",
    "\n",
    "def get_batch():\n",
    "    block_size = model_config[\"block_size\"]\n",
    "    batch_size = train_config[\"batch_size\"]\n",
    "    idx = torch.randint(0, token_data.numel() - block_size - 1, (batch_size,))\n",
    "    x = torch.stack([token_data[i : i + block_size] for i in idx])\n",
    "    y = torch.stack([token_data[i + 1 : i + block_size + 1] for i in idx])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=train_config[\"lr\"])\n",
    "model.train()\n",
    "for step in range(1, train_config[\"max_steps\"] + 1):\n",
    "    t0 = time.time()\n",
    "    x, y = get_batch()\n",
    "    logits, loss = model(x, y)\n",
    "    if not torch.isfinite(loss).item():\n",
    "        print(\"nan loss at step\", step)\n",
    "        break\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    dt = time.time() - t0\n",
    "    tokens_per_sec = (x.numel()) / dt\n",
    "    if step % train_config[\"log_interval\"] == 0 or step == 1:\n",
    "        print(f\"step {step} loss {loss.item():.4f} step_time {dt:.3f}s tok/s {tokens_per_sec:.1f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
